import os
import time
import torch
from PIL import Image
import numpy as np
import torchvision
from torchvision import transforms as T
from torchvision.transforms import functional as F

from torchvision.models.detection.faster_rcnn import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator
from .resnet18_backbone import resnet18

from .model import UNet
from . import config

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

#DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
DEVICE = torch.device("cpu")
print(f"Using device: {DEVICE}")


def build_faster_rcnn_model(num_classes: int, weight_path: str, device: str):
    try:
        backbone = resnet18(pretrained=False)
        backbone.out_channels = 512
        
        anchor_generator = AnchorGenerator(
            sizes=((16, 32, 64, 128),),
            aspect_ratios=((0.5, 1.0, 2.0),),
        )

        model = FasterRCNN(
            backbone,
            num_classes=num_classes,
            rpn_anchor_generator=anchor_generator
        )

        print(f"✅ Loading Faster R-CNN weights: {weight_path}")
        model.load_state_dict(torch.load(weight_path, map_location=device))
        model.to(device)
        model.eval()
        return model
    except Exception as e:
        print(f"❌ Faster R-CNNロードエラー: {e}")
        return None


def build_unet_model(num_keypoints: int, weight_path: str, device: str):
    try:
        model = UNet(in_channels=3, out_channels=num_keypoints).to(device)
        print(f"✅ Loading UNet weights: {weight_path}")
        model.load_state_dict(torch.load(weight_path, map_location=device))
        model.to(device)
        model.eval()
        return model
    except Exception as e:
        print(f"❌ UNetロードエラー: {e}")
        return None

def load_ml_model():
    # Faster R-CNN
    # モデルファイルのパスを取得（detect.pyと同じディレクトリ）
    current_dir = os.path.dirname(os.path.abspath(__file__))
    FASTER_RCNN_WEIGHTS = os.path.join(current_dir, "fasterrcnn_resnet18_adam_20.pth")
    global face_detector, landmark_detector, UNET_WEIGHTS, UNET_TRANSFORM
    face_detector = build_faster_rcnn_model(num_classes=2, weight_path=FASTER_RCNN_WEIGHTS, device=DEVICE)

    # UNet
    UNET_WEIGHTS = os.path.join(current_dir, "unet_epoch_22.pth")
    landmark_detector = build_unet_model(
        num_keypoints=config.NUM_KEYPOINTS, 
        weight_path=UNET_WEIGHTS, 
        device=DEVICE
    )

    UNET_TRANSFORM = T.Compose([
        T.Resize(config.IMAGE_SIZE),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])


def decode_heatmaps_to_coordinates(heatmaps: torch.Tensor) -> np.ndarray:
    _, num_keypoints, H, W = heatmaps.shape
    flat_heatmaps = heatmaps.view(1, num_keypoints, -1)
    max_indices = torch.argmax(flat_heatmaps, dim=2)
    y_coords = max_indices // W
    x_coords = max_indices % W
    
    x_coords = (x_coords.float() + 0.5)
    y_coords = (y_coords.float() + 0.5)
    
    coordinates = torch.stack((x_coords, y_coords), dim=2).squeeze(0) # [C, 2]
    return coordinates.numpy()


def detect_face_and_lndmk(image_path: str, score_threshold: float = 0.3):
    start_time = time.time()
    
    if face_detector is None or landmark_detector is None:
        print("❌ 必要なモデルがロードされていません。")
        return None

    try:
        img_original = Image.open(image_path).convert("RGB")
    except FileNotFoundError:
        print(f"❌ 画像ファイルが見つかりません: {image_path}")
        return None
    
    W, H = img_original.size
    image_load_time = time.time()
    print(f"⏱️ 画像読み込み時間: {(image_load_time - start_time) * 1000:.2f}ms")
    
    img_tensor = F.to_tensor(img_original).to(DEVICE)

    # Faster R-CNN（顔検出）
    face_detect_start = time.time()
    with torch.no_grad():
        outputs = face_detector([img_tensor])
    face_detect_time = time.time()
    print(f"⏱️ Faster R-CNN（顔検出）時間: {(face_detect_time - face_detect_start) * 1000:.2f}ms")

    output = outputs[0]
    boxes = output["boxes"].cpu().numpy()
    scores = output["scores"].cpu().numpy()
    
    if len(scores) == 0:
        print("⚠️ No detections found.")
        return None
    
    best_idx = np.argmax(scores)
    best_box = boxes[best_idx]
    best_score = scores[best_idx]

    if best_score < score_threshold:
        print(f"⚠️ No box above threshold ({best_score:.2f} < {score_threshold})")
        return None
    
    xmin, ymin, xmax, ymax = best_box.astype(float)
    
    xmin_int = max(0, int(xmin))
    ymin_int = max(0, int(ymin))
    xmax_int = min(W, int(xmax))
    ymax_int = min(H, int(ymax))

    
    cropped_img_pil = img_original.crop((xmin_int, ymin_int, xmax_int, ymax_int))
    crop_W, crop_H = cropped_img_pil.size
    
    if crop_W <= 0 or crop_H <= 0:
        print("⚠️ クロップされた領域のサイズが不正です。")
        return None
        
    cropped_img_tensor = UNET_TRANSFORM(cropped_img_pil).unsqueeze(0).to(DEVICE)
    
    # UNet（ランドマーク検出）
    landmark_detect_start = time.time()
    with torch.no_grad():
        heatmaps_pred = landmark_detector(cropped_img_tensor).cpu()
    landmark_detect_time = time.time()
    print(f"⏱️ UNet（ランドマーク検出）時間: {(landmark_detect_time - landmark_detect_start) * 1000:.2f}ms")
        
    relative_landmarks_np = decode_heatmaps_to_coordinates(heatmaps_pred)

    scale_x = crop_W / config.IMAGE_SIZE[1] 
    scale_y = crop_H / config.IMAGE_SIZE[0]
    
    absolute_landmarks_np = relative_landmarks_np.copy()
    absolute_landmarks_np[:, 0] *= scale_x
    absolute_landmarks_np[:, 1] *= scale_y

    absolute_landmarks_np[:, 0] += xmin_int
    absolute_landmarks_np[:, 1] += ymin_int

    
    output_list = [
        [float(xmin), float(ymin)], 
        [float(xmax), float(ymax)]
    ]
    
    for x, y in absolute_landmarks_np:
        output_list.append([float(x), float(y)])
    
    total_time = time.time()
    print(f"✅ 検出完了。BBoxスコア: {best_score:.2f}")
    print(f"⏱️ 総実行時間: {(total_time - start_time) * 1000:.2f}ms")
    print(f"=" * 60)
    
    # 戻り値: (output_list, best_score)
    return output_list, float(best_score)


if __name__ == "__main__":
    test_image = "test.jpg" # 適切な画像パスに変更
    SCORE_THRESHOLD = 0.3

    print("\n--- モデルロード中 ---")
    load_ml_model()
    print("\n--- 推論開始 ---")
    result = detect_face_and_lndmk(test_image, score_threshold=SCORE_THRESHOLD)
    
    if result is not None:
        print(f"要素数: {len(result)}")
        print(f"BBox (左上): {result[0]}")
        print(f"BBox (右下): {result[1]}")
        print(f"ランドマーク (9点) : {result[2:]}") #ここの9点がランドマークの座標
    else:
        print("❌ 処理失敗、または閾値未満の検出結果でした。")


#from detect import load_ml_model, detect_face_and_lndmk